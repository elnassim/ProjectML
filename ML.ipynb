{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération de 40000 enregistrements avec le script ...\n",
      "\n",
      "--- Statistiques Descriptives du Revenu Annuel  ---\n",
      "count     40000.000000\n",
      "mean      23234.973550\n",
      "std       31689.439974\n",
      "min         200.000000\n",
      "25%        5155.000000\n",
      "50%        9419.500000\n",
      "75%       30203.000000\n",
      "max      700000.000000\n",
      "Name: Revenu_Annuel, dtype: float64\n",
      "\n",
      "Moyennes par Milieu :\n",
      "Milieu\n",
      "Rural     22149.102970\n",
      "Urbain    23963.650457\n",
      "Name: Revenu_Annuel, dtype: float64\n",
      "\n",
      "Moyennes par CSP :\n",
      "CSP\n",
      "Cadres supérieurs             110439.000631\n",
      "Professions intermédiaires     41111.379008\n",
      "Employés                       18994.951390\n",
      "Ouvriers                        6637.720935\n",
      "Inactifs                        4499.000000\n",
      "Agriculteurs                    4181.118777\n",
      "Name: Revenu_Annuel, dtype: float64\n",
      "\n",
      "Moyennes par Niveau d'éducation :\n",
      "Niveau_education\n",
      "Supérieur      68052.903471\n",
      "Secondaire     21305.731931\n",
      "Fondamental     5933.697770\n",
      "Sans niveau     3753.893059\n",
      "Name: Revenu_Annuel, dtype: float64\n",
      "\n",
      "Dataset 'dataset_revenu_marocains.csv' généré avec succès (40000 enregistrements).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import uuid  # Ajout de l'import uuid pour générer des adresses email uniques\n",
    "\n",
    "# --- Paramètres Généraux ---\n",
    "N_RECORDS = 40000\n",
    "FILENAME = \"dataset_revenu_marocains.csv\"\n",
    "RANDOM_SEED = 42 # Pour la reproductibilité\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# --- Définition des Catégories ---\n",
    "MILIEU_OPTS = ['Urbain', 'Rural']\n",
    "SEXE_OPTS = ['Homme', 'Femme']\n",
    "NIVEAU_EDUCATION_OPTS = ['Sans niveau', 'Fondamental', 'Secondaire', 'Supérieur']\n",
    "ETAT_MATRIMONIAL_OPTS = ['Célibataire', 'Marié', 'Divorcé', 'Veuf']\n",
    "CSP_OPTS = ['Cadres supérieurs', 'Professions intermédiaires', 'Employés', 'Ouvriers', 'Agriculteurs', 'Inactifs']\n",
    "REGION_GEO_OPTS = ['Nord', 'Centre', 'Sud', 'Est', 'Ouest']\n",
    "SECTEUR_EMPLOI_OPTS = ['Public', 'Privé', 'Informel']\n",
    "OUI_NON_OPTS = ['Oui', 'Non']\n",
    "\n",
    "# --- Proportions pour la génération (peuvent être ajustées) ---\n",
    "P_URBAIN = 0.60 # Proportion cible d'urbains (ajustable)\n",
    "P_RURAL = 1 - P_URBAIN\n",
    "\n",
    "# --- Fonctions de Génération des Caractéristiques (similaires à v1, avec ajustements si besoin) ---\n",
    "\n",
    "def generate_age(n):\n",
    "    return np.random.randint(18, 64, n)\n",
    "\n",
    "def generate_milieu(n):\n",
    "    return np.random.choice(MILIEU_OPTS, n, p=[P_URBAIN, P_RURAL])\n",
    "\n",
    "def generate_sexe(n):\n",
    "    return np.random.choice(SEXE_OPTS, n, p=[0.52, 0.48])\n",
    "\n",
    "def generate_niveau_education(n):\n",
    "    return np.random.choice(NIVEAU_EDUCATION_OPTS, n, p=[0.15, 0.30, 0.35, 0.20]) # Un peu plus de 'Supérieur'\n",
    "\n",
    "def generate_annees_experience(age, niveau_education):\n",
    "    experience = []\n",
    "    for a, edu in zip(age, niveau_education):\n",
    "        min_age_travail = 18\n",
    "        if edu == 'Supérieur': min_age_travail = 23\n",
    "        elif edu == 'Secondaire': min_age_travail = 20\n",
    "        \n",
    "        max_exp = a - min_age_travail\n",
    "        if max_exp < 0: max_exp = 0\n",
    "        \n",
    "        exp = np.random.randint(0, max_exp + 1) if max_exp > 0 else 0\n",
    "        exp = min(exp, a - 16) if a > 16 else 0\n",
    "        experience.append(max(0,exp))\n",
    "    return np.array(experience)\n",
    "\n",
    "def generate_etat_matrimonial(n, age):\n",
    "    etats = []\n",
    "    for a in age:\n",
    "        if a < 25: etats.append(np.random.choice(ETAT_MATRIMONIAL_OPTS, p=[0.8, 0.15, 0.03, 0.02]))\n",
    "        elif a < 45: etats.append(np.random.choice(ETAT_MATRIMONIAL_OPTS, p=[0.2, 0.65, 0.1, 0.05]))\n",
    "        else: etats.append(np.random.choice(ETAT_MATRIMONIAL_OPTS, p=[0.1, 0.55, 0.15, 0.2]))\n",
    "    return np.array(etats)\n",
    "\n",
    "def generate_csp(niveau_education, annees_experience, age):\n",
    "    csps = []\n",
    "    for edu, exp, a in zip(niveau_education, annees_experience, age):\n",
    "        if exp < 1 and a < 22 and edu in ['Sans niveau', 'Fondamental']: csps.append('Inactifs')\n",
    "        elif edu == 'Supérieur':\n",
    "            if exp > 8: csps.append('Cadres supérieurs')\n",
    "            elif exp > 2: csps.append('Professions intermédiaires')\n",
    "            else: csps.append(np.random.choice(['Employés', 'Professions intermédiaires'], p=[0.7,0.3]))\n",
    "        elif edu == 'Secondaire':\n",
    "            if exp > 12: csps.append('Professions intermédiaires')\n",
    "            elif exp > 4: csps.append('Employés')\n",
    "            else: csps.append(np.random.choice(['Ouvriers','Employés'], p=[0.7,0.3]))\n",
    "        elif edu == 'Fondamental':\n",
    "            if exp > 8: csps.append('Ouvriers')\n",
    "            else: csps.append(np.random.choice(['Ouvriers', 'Agriculteurs'], p=[0.6,0.4]))\n",
    "        else: # Sans niveau\n",
    "            csps.append(np.random.choice(['Ouvriers', 'Agriculteurs', 'Inactifs'], p=[0.35,0.35,0.3]))\n",
    "    return np.array(csps)\n",
    "\n",
    "def generate_possession_biens(n, csp_list, milieu_list):\n",
    "    prop_immo, veh_motor, terr_agri = [], [], []\n",
    "    for csp, milieu in zip(csp_list, milieu_list):\n",
    "        p_immo, p_veh, p_agri = 0.05, 0.05, 0.02\n",
    "        if csp == 'Cadres supérieurs': p_immo, p_veh = 0.7, 0.8\n",
    "        elif csp == 'Professions intermédiaires': p_immo, p_veh = 0.5, 0.6\n",
    "        elif csp == 'Employés': p_immo, p_veh = 0.25, 0.35\n",
    "        elif csp == 'Ouvriers': p_immo, p_veh = 0.1, 0.15\n",
    "        elif csp == 'Agriculteurs': p_immo, p_veh, p_agri = 0.3, 0.25, 0.6\n",
    "        \n",
    "        if milieu == 'Rural':\n",
    "            p_veh *= 0.7\n",
    "            if csp == 'Agriculteurs': p_agri = 0.8\n",
    "        \n",
    "        prop_immo.append(np.random.choice(OUI_NON_OPTS, p=[p_immo, 1-p_immo]))\n",
    "        veh_motor.append(np.random.choice(OUI_NON_OPTS, p=[p_veh, 1-p_veh]))\n",
    "        terr_agri.append(np.random.choice(OUI_NON_OPTS, p=[p_agri, 1-p_agri]))\n",
    "    return prop_immo, veh_motor, terr_agri\n",
    "\n",
    "def generate_region_geographique(n):\n",
    "    return np.random.choice(REGION_GEO_OPTS, n, p=[0.22, 0.28, 0.15, 0.15, 0.20]) # Nord, Centre, Sud, Est, Ouest\n",
    "\n",
    "def generate_secteur_emploi(n, csp_list):\n",
    "    secteurs = []\n",
    "    for csp in csp_list:\n",
    "        if csp == 'Inactifs': secteurs.append(np.nan)\n",
    "        elif csp == 'Agriculteurs': secteurs.append(np.random.choice(['Privé', 'Informel'], p=[0.2,0.8]))\n",
    "        elif csp in ['Cadres supérieurs', 'Professions intermédiaires']: secteurs.append(np.random.choice(['Public', 'Privé'], p=[0.35, 0.65]))\n",
    "        elif csp == 'Employés': secteurs.append(np.random.choice(['Public', 'Privé', 'Informel'], p=[0.3, 0.5, 0.2]))\n",
    "        else: secteurs.append(np.random.choice(['Privé', 'Informel'], p=[0.4, 0.6]))\n",
    "    return np.array(secteurs)\n",
    "\n",
    "def generate_revenu_secondaire(n, csp_list):\n",
    "    probs = []\n",
    "    for csp in csp_list:\n",
    "        if csp in ['Cadres supérieurs', 'Professions intermédiaires']: probs.append(0.35)\n",
    "        elif csp == 'Agriculteurs': probs.append(0.25)\n",
    "        elif csp == 'Employés': probs.append(0.15)\n",
    "        else: probs.append(0.05)\n",
    "    return np.array([np.random.choice(OUI_NON_OPTS, p=[p, 1-p]) for p in probs])\n",
    "\n",
    "# --- Nouvelle Fonction de Génération du Revenu Annuel ---\n",
    "def generate_revenu_annuel(df):\n",
    "    n = len(df)\n",
    "    revenus = np.zeros(n)\n",
    "\n",
    "    # Revenu de base avec moins de variance\n",
    "    base_revenu = np.random.lognormal(mean=np.log(1500), sigma=0.05, size=n)  # Réduction de sigma\n",
    "\n",
    "    for i in range(n):\n",
    "        record = df.iloc[i]\n",
    "        rev_i = base_revenu[i]\n",
    "\n",
    "        # Impact du Milieu\n",
    "        milieu_bonus = 2000 if record['Milieu'] == 'Urbain' else 500  # Valeurs fixes\n",
    "        rev_i += milieu_bonus\n",
    "\n",
    "        # Impact Niveau d'Éducation\n",
    "        if record['Niveau_education'] == 'Supérieur':\n",
    "            rev_i += 15000 * (1 + 0.1 * record['Annees_experience'])\n",
    "        elif record['Niveau_education'] == 'Secondaire':\n",
    "            rev_i += 6000 * (1 + 0.07 * record['Annees_experience'])\n",
    "        elif record['Niveau_education'] == 'Fondamental':\n",
    "            rev_i += 2000 * (1 + 0.05 * record['Annees_experience'])\n",
    "        else:\n",
    "            rev_i += 500 * (1 + 0.03 * record['Annees_experience'])\n",
    "\n",
    "        # Impact CSP\n",
    "        csp_factor = {\n",
    "            'Cadres supérieurs': 2.0,\n",
    "            'Professions intermédiaires': 1.6,\n",
    "            'Employés': 1.2,\n",
    "            'Ouvriers': 0.9,\n",
    "            'Agriculteurs': 0.8,\n",
    "            'Inactifs': 1.0\n",
    "        }.get(record['CSP'], 1.0)\n",
    "        rev_i *= csp_factor\n",
    "\n",
    "        # Impact Sexe\n",
    "        rev_i *= 1.2 if record['Sexe'] == 'Homme' else 0.95\n",
    "\n",
    "        # Impact Région\n",
    "        region_factor = {\n",
    "            'Centre': 1.1,\n",
    "            'Ouest': 1.1,\n",
    "            'Nord': 1.05,\n",
    "            'Sud': 0.95,\n",
    "            'Est': 0.95\n",
    "        }.get(record['Region_geographique'], 1.0)\n",
    "        rev_i *= region_factor\n",
    "\n",
    "        # Impact Secteur Emploi\n",
    "        if pd.notna(record['Secteur_emploi']) and record['CSP'] != 'Inactifs':\n",
    "            secteur_factor = {\n",
    "                'Public': 1.05,\n",
    "                'Privé': 1.1,\n",
    "                'Informel': 0.8\n",
    "            }.get(record['Secteur_emploi'], 1.0)\n",
    "            rev_i *= secteur_factor\n",
    "\n",
    "        # Impact Revenu Secondaire\n",
    "        if record['Revenu_secondaire'] == 'Oui':\n",
    "            rev_i += 3000  # Valeur fixe\n",
    "\n",
    "        # Plafonnement et plancher\n",
    "        rev_i = max(300, min(rev_i, 600000))\n",
    "        revenus[i] = round(rev_i, 0)\n",
    "\n",
    "    return revenus\n",
    "\n",
    "# --- Fonctions pour Imperfections (améliorées) ---\n",
    "def add_valeurs_manquantes(df, colonnes_pour_nan, p_nan=0.001):\n",
    "    \"\"\"Ajoute des valeurs manquantes (NaN) de manière aléatoire dans les colonnes spécifiées.\"\"\"\n",
    "    for col in colonnes_pour_nan:\n",
    "        if col in df.columns:\n",
    "            mask = np.random.choice([True, False], size=len(df), p=[p_nan, 1-p_nan])\n",
    "            df.loc[mask, col] = np.nan\n",
    "    return df\n",
    "\n",
    "def add_valeurs_aberrantes_age(df, p_aberrant=0.001):\n",
    "    \"\"\"Ajoute des valeurs aberrantes dans la colonne 'Age'.\"\"\"\n",
    "    n_aberr = int(p_aberrant * len(df))\n",
    "    valid_indices = df.index.tolist()\n",
    "    aberr_indices = random.sample(valid_indices, min(n_aberr, len(valid_indices)))\n",
    "    for idx in aberr_indices:\n",
    "        df.loc[idx, 'Age'] = np.random.choice([-5, 150])  # Valeurs aberrantes\n",
    "    return df\n",
    "\n",
    "def add_valeurs_aberrantes_experience(df, p_aberrant=0.001):\n",
    "    \"\"\"Ajoute des valeurs aberrantes dans la colonne 'Annees_experience', en tenant compte de l'âge.\"\"\"\n",
    "    n_aberr = int(p_aberrant * len(df))\n",
    "    valid_indices = df.index.tolist()\n",
    "    aberr_indices = random.sample(valid_indices, min(n_aberr, len(valid_indices)))\n",
    "    for idx in aberr_indices:\n",
    "        age = df.loc[idx, 'Age']\n",
    "        df.loc[idx, 'Annees_experience'] = age + np.random.randint(10, 30)  # Expérience > Age\n",
    "    return df\n",
    "\n",
    "def add_valeurs_aberrantes_possession(df, p_aberrant=0.001):\n",
    "    \"\"\"Ajoute des valeurs aberrantes dans les colonnes de possession de biens, en tenant compte de la CSP.\"\"\"\n",
    "    n_aberr = int(p_aberrant * len(df))\n",
    "    valid_indices = df.index.tolist()\n",
    "    aberr_indices = random.sample(valid_indices, min(n_aberr, len(valid_indices)))\n",
    "    for idx in aberr_indices:\n",
    "        csp = df.loc[idx, 'CSP']\n",
    "        if csp == 'Inactifs':\n",
    "            df.loc[idx, 'Propriete_immobiliere'] = np.random.choice(['Oui', 'Non'], p=[0.9, 0.1])\n",
    "            df.loc[idx, 'Vehicule_motorise'] = np.random.choice(['Oui', 'Non'], p=[0.8, 0.2])\n",
    "            df.loc[idx, 'Terrain_agricole'] = np.random.choice(['Oui', 'Non'], p=[0.1, 0.9])\n",
    "        elif csp == 'Agriculteurs':\n",
    "            df.loc[idx, 'Terrain_agricole'] = np.random.choice(['Oui', 'Non'], p=[0.05, 0.95])\n",
    "    return df\n",
    "\n",
    "def add_valeurs_aberrantes_revenu(revenus_col, csp_col, p_aberrant=0.0005):\n",
    "    \"\"\"Ajoute des valeurs aberrantes dans la colonne 'Revenu_Annuel', en tenant compte de la CSP.\"\"\"\n",
    "    n_aberr = int(p_aberrant * len(revenus_col))\n",
    "    valid_indices = revenus_col[revenus_col.notna()].index.tolist()\n",
    "    aberr_indices = random.sample(valid_indices, min(n_aberr, len(valid_indices)))\n",
    "    \n",
    "    for idx in aberr_indices:\n",
    "        csp = csp_col.loc[idx]\n",
    "        if csp == 'Inactifs':\n",
    "            revenus_col.loc[idx] = np.random.choice([100, 200, 300])\n",
    "        elif csp == 'Cadres supérieurs':\n",
    "            revenus_col.loc[idx] = np.random.choice([1000000, 1200000, 1500000])\n",
    "        elif csp == 'Professions intermédiaires':\n",
    "            revenus_col.loc[idx] = np.random.choice([600000, 700000])\n",
    "        elif csp == 'Employés':\n",
    "            revenus_col.loc[idx] = np.random.choice([400000, 500000])\n",
    "        elif csp == 'Ouvriers':\n",
    "            revenus_col.loc[idx] = np.random.choice([200000, 300000])\n",
    "        elif csp == 'Agriculteurs':\n",
    "            revenus_col.loc[idx] = np.random.choice([50000, 60000])\n",
    "        else:\n",
    "            revenus_col.loc[idx] = np.random.choice([300000, 400000, 500000])\n",
    "    return revenus_col\n",
    "\n",
    "# --- Génération du Dataset  ---\n",
    "def generate_dataset():\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    data['Age'] = generate_age(N_RECORDS)\n",
    "    data['Milieu'] = generate_milieu(N_RECORDS)\n",
    "    data['Sexe'] = generate_sexe(N_RECORDS)\n",
    "    data['Niveau_education'] = generate_niveau_education(N_RECORDS)\n",
    "    data['Annees_experience'] = generate_annees_experience(data['Age'], data['Niveau_education'])\n",
    "    data['Etat_matrimonial'] = generate_etat_matrimonial(N_RECORDS, data['Age'])\n",
    "    data['CSP'] = generate_csp(data['Niveau_education'], data['Annees_experience'], data['Age'])\n",
    "    \n",
    "    prop_immo, veh_motor, terr_agri = generate_possession_biens(N_RECORDS, data['CSP'], data['Milieu'])\n",
    "    data['Propriete_immobiliere'] = prop_immo\n",
    "    data['Vehicule_motorise'] = veh_motor\n",
    "    data['Terrain_agricole'] = terr_agri\n",
    "\n",
    "    data['Region_geographique'] = generate_region_geographique(N_RECORDS)\n",
    "    data['Secteur_emploi'] = generate_secteur_emploi(N_RECORDS, data['CSP'])\n",
    "    data['Revenu_secondaire'] = generate_revenu_secondaire(N_RECORDS, data['CSP'])\n",
    "    \n",
    "    data['Revenu_Annuel'] = generate_revenu_annuel(data.copy()) # Utilise la nouvelle fonction\n",
    "\n",
    "    # Imperfections\n",
    "    cols_with_nan = ['Etat_matrimonial', 'Secteur_emploi', 'Revenu_secondaire', \n",
    "                     'Propriete_immobiliere', 'Vehicule_motorise', 'Terrain_agricole',\n",
    "                     'Annees_experience'] # CSP peut avoir des Inactifs, pas besoin de NaN explicite\n",
    "    data = add_valeurs_manquantes(data, cols_with_nan, p_nan=0.001)\n",
    "    \n",
    "    # Aberrations sur le revenu (après génération et NaN)\n",
    "    revenu_not_na_mask = data['Revenu_Annuel'].notna()\n",
    "    data.loc[revenu_not_na_mask, 'Revenu_Annuel'] = add_valeurs_aberrantes_revenu(\n",
    "        data.loc[revenu_not_na_mask, 'Revenu_Annuel'].copy(),\n",
    "        data.loc[revenu_not_na_mask, 'CSP'].copy()\n",
    "    )\n",
    "\n",
    "    # AJOUT : Aberrations sur d'autres colonnes\n",
    "    data = add_valeurs_aberrantes_age(data, p_aberrant=0.001)\n",
    "    data = add_valeurs_aberrantes_experience(data, p_aberrant=0.001)\n",
    "    data = add_valeurs_aberrantes_possession(data, p_aberrant=0.001)\n",
    "\n",
    "    # Colonne dérivée utile pour EDA, mais pas pour modélisation directe si Age est déjà là\n",
    "    bins = [18, 25, 45, 60, 100] # 100 pour couvrir les âges aberrants\n",
    "    labels = ['Jeune', 'Adulte', 'Senior', 'Âgé']\n",
    "    data['Categorie_age'] = pd.cut(data['Age'], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    # Vérification finale de cohérence pour Annees_experience vs Age\n",
    "    mask_exp_incoherent = data['Annees_experience'] > (data['Age'] - 16)\n",
    "    data.loc[mask_exp_incoherent, 'Annees_experience'] = (data.loc[mask_exp_incoherent, 'Age'] - 16 - np.random.randint(0,2, size=mask_exp_incoherent.sum())).clip(lower=0)\n",
    "    \n",
    "    # S'assurer que les inactifs ont bien un revenu bas ou NaN\n",
    "    inactifs_mask = data['CSP'] == 'Inactifs'\n",
    "    if 'Revenu_Annuel' in data.columns:\n",
    "        data.loc[inactifs_mask & data['Revenu_Annuel'].notna(), 'Revenu_Annuel'] = \\\n",
    "            data.loc[inactifs_mask & data['Revenu_Annuel'].notna(), 'Revenu_Annuel'].apply(lambda x: min(x, 12000))\n",
    "\n",
    "    # AJOUT: Colonnes Redondantes et Non Pertinentes\n",
    "    data['Revenu_Mensuel'] = (data['Revenu_Annuel'] / 12).round(2)\n",
    "    data['Adresse_Email'] = [f\"user{uuid.uuid4().hex[:6]}@example.com\" for _ in range(N_RECORDS)]\n",
    "    data['CIN'] = [f\"{random.choice('ABCDEFGHIJKLMNOPQRSTUVWXYZ')}{random.choice('ABCDEFGHIJKLMNOPQRSTUVWXYZ')}{random.randint(100000,999999)}\" for _ in range(N_RECORDS)]\n",
    "\n",
    "    ordered_columns = [\n",
    "        'Age', 'Categorie_age', 'Sexe', 'Milieu', 'Region_geographique', 'Etat_matrimonial',\n",
    "        'Niveau_education', 'Annees_experience', 'CSP', 'Secteur_emploi',\n",
    "        'Propriete_immobiliere', 'Vehicule_motorise', 'Terrain_agricole',\n",
    "        'Revenu_secondaire', 'Revenu_Annuel', 'Revenu_Mensuel',  # Ajout de Revenu_Mensuel\n",
    "        'Adresse_Email', 'CIN'  # Ajout de Adresse_Email et CIN\n",
    "    ]\n",
    "    final_columns = [col for col in ordered_columns if col in data.columns]\n",
    "    missing_cols = [col for col in data.columns if col not in final_columns] # Au cas où\n",
    "    data = data[final_columns + missing_cols]\n",
    "\n",
    "    return data\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Génération de {N_RECORDS} enregistrements avec le script ...\")\n",
    "    dataset = generate_dataset()\n",
    "    \n",
    "    print(\"\\n--- Statistiques Descriptives du Revenu Annuel  ---\")\n",
    "    print(dataset['Revenu_Annuel'].describe())\n",
    "    \n",
    "    print(\"\\nMoyennes par Milieu :\")\n",
    "    print(dataset.groupby('Milieu')['Revenu_Annuel'].mean())\n",
    "\n",
    "    print(\"\\nMoyennes par CSP :\")\n",
    "    print(dataset.groupby('CSP')['Revenu_Annuel'].mean().sort_values(ascending=False))\n",
    "\n",
    "    print(\"\\nMoyennes par Niveau d'éducation :\")\n",
    "    print(dataset.groupby('Niveau_education')['Revenu_Annuel'].mean().sort_values(ascending=False))\n",
    "\n",
    "    dataset.to_csv(FILENAME, index=False, encoding='utf-8')\n",
    "    print(f\"\\nDataset '{FILENAME}' généré avec succès ({len(dataset)} enregistrements).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exécution du script de prétraitement...\n",
      "Dataset chargé avec succès.\n",
      "Variable cible et caractéristiques séparées.\n",
      "Données divisées : X_train shape (32000, 13), X_test shape (8000, 13)\n",
      "Colonnes numériques identifiées : ['Age', 'Annees_experience']\n",
      "Colonnes catégorielles identifiées : ['Sexe', 'Milieu', 'Region_geographique', 'Etat_matrimonial', 'Niveau_education', 'CSP', 'Secteur_emploi', 'Propriete_immobiliere', 'Vehicule_motorise', 'Terrain_agricole', 'Revenu_secondaire']\n",
      "Imputation des valeurs manquantes numériques terminée (médiane).\n",
      "Imputation des valeurs manquantes catégorielles terminée (mode).\n",
      "Encodage One-Hot terminé.\n",
      "Colonnes alignées entre les ensembles d'entraînement et de test.\n",
      "Nouvelles dimensions après encodage : X_train shape (32000, 36), X_test shape (8000, 36)\n",
      "Standardisation des colonnes numériques d'origine terminée.\n",
      "Prétraitement terminé.\n",
      "\n",
      "--- Informations sur les données prétraitées ---\n",
      "X_train shape: (32000, 36)\n",
      "X_test shape: (8000, 36)\n",
      "y_train shape: (32000,)\n",
      "y_test shape: (8000,)\n",
      "\n",
      "Premières lignes de X_train (après prétraitement):\n",
      "            Age  Annees_experience  Sexe_Femme  Sexe_Homme  Milieu_Rural  \\\n",
      "14307 -0.334733           0.170054       False        True          True   \n",
      "17812  1.260070           1.902895       False        True         False   \n",
      "11020  1.639786           2.718350       False        True         False   \n",
      "15158  1.032241           1.393236       False        True         False   \n",
      "24990  0.120925          -0.441537        True       False         False   \n",
      "\n",
      "       Milieu_Urbain  Region_geographique_Centre  Region_geographique_Est  \\\n",
      "14307          False                       False                    False   \n",
      "17812           True                       False                    False   \n",
      "11020           True                       False                    False   \n",
      "15158           True                       False                    False   \n",
      "24990           True                       False                    False   \n",
      "\n",
      "       Region_geographique_Nord  Region_geographique_Ouest  ...  \\\n",
      "14307                      True                      False  ...   \n",
      "17812                     False                      False  ...   \n",
      "11020                      True                      False  ...   \n",
      "15158                     False                      False  ...   \n",
      "24990                      True                      False  ...   \n",
      "\n",
      "       Secteur_emploi_Privé  Secteur_emploi_Public  Propriete_immobiliere_Non  \\\n",
      "14307                 False                  False                       True   \n",
      "17812                  True                  False                       True   \n",
      "11020                 False                  False                      False   \n",
      "15158                 False                   True                      False   \n",
      "24990                 False                  False                       True   \n",
      "\n",
      "       Propriete_immobiliere_Oui  Vehicule_motorise_Non  \\\n",
      "14307                      False                   True   \n",
      "17812                      False                  False   \n",
      "11020                       True                   True   \n",
      "15158                       True                  False   \n",
      "24990                      False                   True   \n",
      "\n",
      "       Vehicule_motorise_Oui  Terrain_agricole_Non  Terrain_agricole_Oui  \\\n",
      "14307                  False                 False                  True   \n",
      "17812                   True                  True                 False   \n",
      "11020                  False                 False                  True   \n",
      "15158                   True                  True                 False   \n",
      "24990                  False                  True                 False   \n",
      "\n",
      "       Revenu_secondaire_Non  Revenu_secondaire_Oui  \n",
      "14307                   True                  False  \n",
      "17812                   True                  False  \n",
      "11020                  False                   True  \n",
      "15158                  False                   True  \n",
      "24990                   True                  False  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "\n",
      "Statistiques de y_train:\n",
      "count     32000.000000\n",
      "mean      23161.359125\n",
      "std       30734.539230\n",
      "min         100.000000\n",
      "25%        5157.000000\n",
      "50%        9503.000000\n",
      "75%       30287.250000\n",
      "max      300000.000000\n",
      "Name: Revenu_Annuel, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def load_and_preprocess_data(file_path=\"dataset_revenu_marocains_.csv\"):\n",
    "    \"\"\"\n",
    "    Charge et prétraite le dataset pour la modélisation.\n",
    "    \"\"\"\n",
    "    # 1. Charger le dataset\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur : Le fichier '{file_path}' n'a pas été trouvé. Veuillez d'abord exécuter generate_dataset_.py.\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    print(\"Dataset chargé avec succès.\")\n",
    "\n",
    "    # 2. Séparer X et y, et supprimer 'Categorie_age'\n",
    "    if 'Revenu_Annuel' not in df.columns:\n",
    "        print(\"Erreur : La colonne 'Revenu_Annuel' (cible) est manquante dans le dataset.\")\n",
    "        return None, None, None, None\n",
    "        \n",
    "    y = df['Revenu_Annuel'].copy()\n",
    "    X = df.drop(columns=['Revenu_Annuel', 'Categorie_age'], errors='ignore')\n",
    "    print(\"Variable cible et caractéristiques séparées.\")\n",
    "\n",
    "    # 3. Diviser en ensembles d'entraînement et de test (avant toute imputation/scaling)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Données divisées : X_train shape {X_train.shape}, X_test shape {X_test.shape}\")\n",
    "\n",
    "    # Faire des copies pour éviter SettingWithCopyWarning lors des modifications\n",
    "    X_train = X_train.copy()\n",
    "    X_test = X_test.copy()\n",
    "\n",
    "    # 4. Identifier les types de colonnes à partir de X_train\n",
    "    numerical_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    print(f\"Colonnes numériques identifiées : {numerical_cols}\")\n",
    "    print(f\"Colonnes catégorielles identifiées : {categorical_cols}\")\n",
    "\n",
    "    # 5. Imputation des valeurs manquantes\n",
    "    # Imputation numérique\n",
    "    if numerical_cols:\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        X_train[numerical_cols] = num_imputer.fit_transform(X_train[numerical_cols])\n",
    "        X_test[numerical_cols] = num_imputer.transform(X_test[numerical_cols])\n",
    "        print(\"Imputation des valeurs manquantes numériques terminée (médiane).\")\n",
    "\n",
    "    # Imputation catégorielle\n",
    "    if categorical_cols:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        X_train[categorical_cols] = cat_imputer.fit_transform(X_train[categorical_cols])\n",
    "        X_test[categorical_cols] = cat_imputer.transform(X_test[categorical_cols])\n",
    "        print(\"Imputation des valeurs manquantes catégorielles terminée (mode).\")\n",
    "\n",
    "    # 6. Encodage One-Hot des variables catégorielles\n",
    "    if categorical_cols:\n",
    "        X_train = pd.get_dummies(X_train, columns=categorical_cols, prefix=categorical_cols, dummy_na=False)\n",
    "        X_test = pd.get_dummies(X_test, columns=categorical_cols, prefix=categorical_cols, dummy_na=False)\n",
    "        print(\"Encodage One-Hot terminé.\")\n",
    "\n",
    "        # 7. Alignement des colonnes après one-hot encoding\n",
    "        # S'assure que X_test a les mêmes colonnes que X_train, dans le même ordre,\n",
    "        # en ajoutant les colonnes manquantes avec 0 et en supprimant celles en trop.\n",
    "        train_cols_after_dummies = X_train.columns.tolist()\n",
    "        X_test = X_test.reindex(columns=train_cols_after_dummies, fill_value=0)\n",
    "        # S'assurer que X_train n'a pas de colonnes qui ne seraient pas dans X_test après réindexation\n",
    "        # (normalement géré par la ligne ci-dessus, mais pour être sûr)\n",
    "        X_train = X_train[train_cols_after_dummies] \n",
    "        print(\"Colonnes alignées entre les ensembles d'entraînement et de test.\")\n",
    "        print(f\"Nouvelles dimensions après encodage : X_train shape {X_train.shape}, X_test shape {X_test.shape}\")\n",
    "\n",
    "\n",
    "    # 8. Standardisation des variables numériques (celles d'origine)\n",
    "    # Ne pas standardiser les colonnes créées par get_dummies (qui sont 0/1)\n",
    "    if numerical_cols: # Utilise la liste originale des colonnes numériques\n",
    "        scaler = StandardScaler()\n",
    "        X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "        X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "        print(\"Standardisation des colonnes numériques d'origine terminée.\")\n",
    "        \n",
    "    # Gestion des NaN dans y (normalement, y ne devrait pas avoir de NaN si la génération est correcte)\n",
    "    # Si y_train ou y_test ont des NaN, cela peut poser problème aux modèles.\n",
    "    # Une stratégie simple est de les supprimer (avec les lignes X correspondantes) AVANT le split.\n",
    "    # Ici, nous supposons que y est propre. Si ce n'est pas le cas, il faudrait ajouter une étape de nettoyage de y.\n",
    "    if y_train.isnull().any() or y_test.isnull().any():\n",
    "        print(\"Attention : Des valeurs NaN sont présentes dans la variable cible y_train ou y_test. Cela peut nécessiter un traitement supplémentaire.\")\n",
    "\n",
    "\n",
    "    print(\"Prétraitement terminé.\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Exécution du script de prétraitement...\")\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "\n",
    "    if X_train is not None:\n",
    "        print(\"\\n--- Informations sur les données prétraitées ---\")\n",
    "        print(\"X_train shape:\", X_train.shape)\n",
    "        print(\"X_test shape:\", X_test.shape)\n",
    "        print(\"y_train shape:\", y_train.shape)\n",
    "        print(\"y_test shape:\", y_test.shape)\n",
    "        \n",
    "        print(\"\\nPremières lignes de X_train (après prétraitement):\")\n",
    "        print(X_train.head())\n",
    "        \n",
    "        print(\"\\nStatistiques de y_train:\")\n",
    "        print(y_train.describe())\n",
    "\n",
    "        # Optionnel : Sauvegarder les fichiers prétraités\n",
    "        # X_train.to_csv(\"X_train_processed.csv\", index=False)\n",
    "        # X_test.to_csv(\"X_test_processed.csv\", index=False)\n",
    "        # y_train.to_csv(\"y_train.csv\", index=False, header=True)\n",
    "        # y_test.to_csv(\"y_test.csv\", index=False, header=True)\n",
    "        # print(\"\\nFichiers prétraités sauvegardés (décommenter pour activer).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données d'entraînement et de test prêtes pour la modélisation.\n",
      "X_train shape: (32000, 36), y_train shape: (32000,)\n",
      "X_test shape: (8000, 36), y_test shape: (8000,)\n"
     ]
    }
   ],
   "source": [
    "# CELLULE 3 : Importations supplémentaires et initialisation pour la modélisation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import time\n",
    "\n",
    "# Pour stocker les performances des modèles\n",
    "model_performance = {}\n",
    "\n",
    "# Définir une constante pour la reproductibilité si nécessaire dans les modèles\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Vérifier si les données sont chargées (elles devraient l'être par la cellule précédente)\n",
    "if 'X_train' not in locals() or \\\n",
    "   'X_test' not in locals() or \\\n",
    "   'y_train' not in locals() or \\\n",
    "   'y_test' not in locals():\n",
    "    print(\"ERREUR : Les données X_train, X_test, y_train, y_test ne sont pas chargées.\")\n",
    "    print(\"Veuillez exécuter la cellule de prétraitement des données (load_and_preprocess_data).\")\n",
    "else:\n",
    "    print(\"Données d'entraînement et de test prêtes pour la modélisation.\")\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.1. Entraînement du Modèle de Régression Linéaire ---\n",
      "Entraînement terminé en 0.16 secondes.\n",
      "\n",
      "--- Évaluation du Modèle de Régression Linéaire ---\n",
      "MAE (Mean Absolute Error): 4758.18 DH\n",
      "RMSE (Root Mean Squared Error): 10938.45 DH\n",
      "R² (Coefficient de détermination): 0.8806\n",
      "\n",
      "--- Aperçu des Prédictions vs Valeurs Réelles (Régression Linéaire) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Réel",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Prédit_LR",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e88d47c8-556b-4bfa-964b-9f02c9ff4314",
       "rows": [
        [
         "0",
         "5191.0",
         "3300.258707705754"
        ],
        [
         "1",
         "6581.0",
         "5060.9567052299535"
        ],
        [
         "2",
         "44592.0",
         "41689.349111205665"
        ],
        [
         "3",
         "7755.0",
         "7252.506818133399"
        ],
        [
         "4",
         "5916.0",
         "6197.278566333203"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Réel</th>\n",
       "      <th>Prédit_LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5191.0</td>\n",
       "      <td>3300.258708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6581.0</td>\n",
       "      <td>5060.956705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44592.0</td>\n",
       "      <td>41689.349111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7755.0</td>\n",
       "      <td>7252.506818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5916.0</td>\n",
       "      <td>6197.278566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Réel     Prédit_LR\n",
       "0   5191.0   3300.258708\n",
       "1   6581.0   5060.956705\n",
       "2  44592.0  41689.349111\n",
       "3   7755.0   7252.506818\n",
       "4   5916.0   6197.278566"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELLULE 4 : 3.1. Régression Linéaire (Modèle de Base)\n",
    "\n",
    "if 'X_train' in locals():\n",
    "    print(\"\\n--- 3.1. Entraînement du Modèle de Régression Linéaire ---\")\n",
    "    \n",
    "    # Initialiser et entraîner le modèle\n",
    "    linear_model = LinearRegression()\n",
    "    \n",
    "    start_time_lr = time.time()\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    end_time_lr = time.time()\n",
    "    \n",
    "    training_time_lr = end_time_lr - start_time_lr\n",
    "    print(f\"Entraînement terminé en {training_time_lr:.2f} secondes.\")\n",
    "    \n",
    "    # Prédictions\n",
    "    predictions_lr = linear_model.predict(X_test)\n",
    "    \n",
    "    # Évaluation\n",
    "    mae_lr = mean_absolute_error(y_test, predictions_lr)\n",
    "    rmse_lr = np.sqrt(mean_squared_error(y_test, predictions_lr))\n",
    "    r2_lr = r2_score(y_test, predictions_lr)\n",
    "    \n",
    "    print(\"\\n--- Évaluation du Modèle de Régression Linéaire ---\")\n",
    "    print(f\"MAE (Mean Absolute Error): {mae_lr:.2f} DH\")\n",
    "    print(f\"RMSE (Root Mean Squared Error): {rmse_lr:.2f} DH\")\n",
    "    print(f\"R² (Coefficient de détermination): {r2_lr:.4f}\")\n",
    "    \n",
    "    # Stocker les performances\n",
    "    model_performance['Linear Regression'] = {\n",
    "        'MAE': mae_lr,\n",
    "        'RMSE': rmse_lr,\n",
    "        'R2': r2_lr,\n",
    "        'Training Time (s)': training_time_lr,\n",
    "        'Best Params': 'N/A'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n--- Aperçu des Prédictions vs Valeurs Réelles (Régression Linéaire) ---\")\n",
    "    df_predictions_lr = pd.DataFrame({'Réel': y_test.values, 'Prédit_LR': predictions_lr})\n",
    "    display(df_predictions_lr.head())\n",
    "else:\n",
    "    print(\"Veuillez d'abord charger et prétraiter les données.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.2. Entraînement et Ajustement des Hyperparamètres pour DecisionTreeRegressor ---\n",
      "Ajustement des hyperparamètres pour DecisionTreeRegressor en cours (CV=5)...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajustement terminé en 5.24 secondes.\n",
      "\n",
      "Meilleurs hyperparamètres trouvés pour DecisionTreeRegressor : {'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Meilleur score (neg_mean_squared_error) de validation croisée : -34773682.8128\n",
      "\n",
      "--- Évaluation du Modèle DecisionTreeRegressor (avec meilleurs hyperparamètres) ---\n",
      "MAE: 2732.17 DH\n",
      "RMSE: 7851.75 DH\n",
      "R²: 0.9385\n",
      "\n",
      "--- Aperçu des Prédictions vs Valeurs Réelles (Decision Tree) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Réel",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Prédit_DT",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "af7a0e17-be7e-4758-9c5f-eaa2ec5cb288",
       "rows": [
        [
         "0",
         "5191.0",
         "5850.070002058884"
        ],
        [
         "1",
         "6581.0",
         "5850.070002058884"
        ],
        [
         "2",
         "44592.0",
         "48508.9890625"
        ],
        [
         "3",
         "7755.0",
         "7893.825495750708"
        ],
        [
         "4",
         "5916.0",
         "5850.070002058884"
        ],
        [
         "5",
         "19169.0",
         "17418.653620352252"
        ],
        [
         "6",
         "36117.0",
         "29110.6642394822"
        ],
        [
         "7",
         "24724.0",
         "17418.653620352252"
        ],
        [
         "8",
         "29488.0",
         "28249.90065681445"
        ],
        [
         "9",
         "123182.0",
         "113072.85641025641"
        ],
        [
         "10",
         "5710.0",
         "5850.070002058884"
        ],
        [
         "11",
         "47042.0",
         "48508.9890625"
        ],
        [
         "12",
         "5702.0",
         "5850.070002058884"
        ],
        [
         "13",
         "5382.0",
         "5850.070002058884"
        ],
        [
         "14",
         "26443.0",
         "17418.653620352252"
        ],
        [
         "15",
         "7735.0",
         "5850.070002058884"
        ],
        [
         "16",
         "49386.0",
         "44260.17495029821"
        ],
        [
         "17",
         "11209.0",
         "17418.653620352252"
        ],
        [
         "18",
         "5768.0",
         "5850.070002058884"
        ],
        [
         "19",
         "32124.0",
         "28249.90065681445"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Réel</th>\n",
       "      <th>Prédit_DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5191.0</td>\n",
       "      <td>5850.070002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6581.0</td>\n",
       "      <td>5850.070002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44592.0</td>\n",
       "      <td>48508.989062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7755.0</td>\n",
       "      <td>7893.825496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5916.0</td>\n",
       "      <td>5850.070002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19169.0</td>\n",
       "      <td>17418.653620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36117.0</td>\n",
       "      <td>29110.664239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24724.0</td>\n",
       "      <td>17418.653620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29488.0</td>\n",
       "      <td>28249.900657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123182.0</td>\n",
       "      <td>113072.856410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5710.0</td>\n",
       "      <td>5850.070002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>47042.0</td>\n",
       "      <td>48508.989062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5702.0</td>\n",
       "      <td>5850.070002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5382.0</td>\n",
       "      <td>5850.070002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26443.0</td>\n",
       "      <td>17418.653620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7735.0</td>\n",
       "      <td>5850.070002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>49386.0</td>\n",
       "      <td>44260.174950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11209.0</td>\n",
       "      <td>17418.653620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5768.0</td>\n",
       "      <td>5850.070002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32124.0</td>\n",
       "      <td>28249.900657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Réel      Prédit_DT\n",
       "0     5191.0    5850.070002\n",
       "1     6581.0    5850.070002\n",
       "2    44592.0   48508.989062\n",
       "3     7755.0    7893.825496\n",
       "4     5916.0    5850.070002\n",
       "5    19169.0   17418.653620\n",
       "6    36117.0   29110.664239\n",
       "7    24724.0   17418.653620\n",
       "8    29488.0   28249.900657\n",
       "9   123182.0  113072.856410\n",
       "10    5710.0    5850.070002\n",
       "11   47042.0   48508.989062\n",
       "12    5702.0    5850.070002\n",
       "13    5382.0    5850.070002\n",
       "14   26443.0   17418.653620\n",
       "15    7735.0    5850.070002\n",
       "16   49386.0   44260.174950\n",
       "17   11209.0   17418.653620\n",
       "18    5768.0    5850.070002\n",
       "19   32124.0   28249.900657"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELLULE 5 : 3.2. Arbres de Décision (DecisionTreeRegressor) avec Ajustement des Hyperparamètres\n",
    "\n",
    "if 'X_train' in locals():\n",
    "    print(\"\\n--- 3.2. Entraînement et Ajustement des Hyperparamètres pour DecisionTreeRegressor ---\")\n",
    "\n",
    "    # Définir la grille d'hyperparamètres selon les spécifications du projet\n",
    "    param_grid_dt = {\n",
    "        'criterion': ['squared_error'], # 'friedman_mse' est aussi une option\n",
    "        'max_depth': [5],\n",
    "        'min_samples_split': [2]\n",
    "    }\n",
    "    # Note: 'absolute_error' pour criterion peut être significativement plus lent.\n",
    "\n",
    "    # Initialiser GridSearchCV\n",
    "    grid_search_dt = GridSearchCV(\n",
    "        estimator=DecisionTreeRegressor(random_state=RANDOM_STATE),\n",
    "        param_grid=param_grid_dt,\n",
    "        cv=5, # Nombre de plis pour la validation croisée\n",
    "        scoring='neg_mean_squared_error', # Métrique pour l'évaluation\n",
    "        n_jobs=-1, # Utiliser tous les processeurs disponibles\n",
    "        verbose=1 # Afficher des messages pendant l'ajustement\n",
    "    )\n",
    "\n",
    "    print(f\"Ajustement des hyperparamètres pour DecisionTreeRegressor en cours (CV={grid_search_dt.cv})...\")\n",
    "    start_time_dt_grid = time.time()\n",
    "    grid_search_dt.fit(X_train, y_train)\n",
    "    end_time_dt_grid = time.time()\n",
    "    grid_search_time_dt = end_time_dt_grid - start_time_dt_grid\n",
    "    print(f\"Ajustement terminé en {grid_search_time_dt:.2f} secondes.\")\n",
    "\n",
    "    # Meilleurs hyperparamètres et score\n",
    "    print(f\"\\nMeilleurs hyperparamètres trouvés pour DecisionTreeRegressor : {grid_search_dt.best_params_}\")\n",
    "    # Le best_score_ est neg_mean_squared_error, donc plus proche de 0 est mieux.\n",
    "    print(f\"Meilleur score (neg_mean_squared_error) de validation croisée : {grid_search_dt.best_score_:.4f}\")\n",
    "    \n",
    "    # Meilleur estimateur\n",
    "    best_dt_model = grid_search_dt.best_estimator_\n",
    "    \n",
    "    # Prédictions sur l'ensemble de test avec le meilleur modèle\n",
    "    predictions_dt = best_dt_model.predict(X_test)\n",
    "    \n",
    "    # Évaluation du meilleur modèle\n",
    "    mae_dt = mean_absolute_error(y_test, predictions_dt)\n",
    "    rmse_dt = np.sqrt(mean_squared_error(y_test, predictions_dt))\n",
    "    r2_dt = r2_score(y_test, predictions_dt)\n",
    "    \n",
    "    print(\"\\n--- Évaluation du Modèle DecisionTreeRegressor (avec meilleurs hyperparamètres) ---\")\n",
    "    print(f\"MAE: {mae_dt:.2f} DH\")\n",
    "    print(f\"RMSE: {rmse_dt:.2f} DH\")\n",
    "    print(f\"R²: {r2_dt:.4f}\")\n",
    "    \n",
    "    # Stocker les performances\n",
    "    model_performance['Decision Tree (Tuned)'] = {\n",
    "        'MAE': mae_dt,\n",
    "        'RMSE': rmse_dt,\n",
    "        'R2': r2_dt,\n",
    "        'Training Time (s)': grid_search_time_dt, # Temps pour GridSearchCV\n",
    "        'Best Params': grid_search_dt.best_params_\n",
    "    }\n",
    "\n",
    "    print(\"\\n--- Aperçu des Prédictions vs Valeurs Réelles (Decision Tree) ---\")\n",
    "    df_predictions_dt = pd.DataFrame({'Réel': y_test.values, 'Prédit_DT': predictions_dt})\n",
    "    display(df_predictions_dt.head(20))\n",
    "else:\n",
    "    print(\"Veuillez d'abord charger et prétraiter les données.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.3. Entraînement et Ajustement des Hyperparamètres pour RandomForestRegressor ---\n",
      "Ajustement des hyperparamètres pour RandomForestRegressor en cours (CV=3)...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Ajustement terminé en 165.90 secondes.\n",
      "\n",
      "Meilleurs hyperparamètres trouvés pour RandomForestRegressor : {'criterion': 'squared_error', 'max_depth': 10, 'n_estimators': 200}\n",
      "Meilleur score (neg_mean_squared_error) de validation croisée : -26128557.4194\n",
      "\n",
      "--- Évaluation du Modèle RandomForestRegressor (avec meilleurs hyperparamètres) ---\n",
      "MAE: 1036.76 DH\n",
      "RMSE: 7202.94 DH\n",
      "R²: 0.9482\n",
      "\n",
      "--- Aperçu des Prédictions vs Valeurs Réelles (Random Forest) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Réel",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Prédit_RF",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "70d80614-faa6-4484-b43e-b23c58e43548",
       "rows": [
        [
         "0",
         "5191.0",
         "4627.772925954269"
        ],
        [
         "1",
         "6581.0",
         "6733.117869975169"
        ],
        [
         "2",
         "44592.0",
         "45384.84678496272"
        ],
        [
         "3",
         "7755.0",
         "7663.381414338276"
        ],
        [
         "4",
         "5916.0",
         "5155.89750227902"
        ],
        [
         "5",
         "19169.0",
         "17345.140658359356"
        ],
        [
         "6",
         "36117.0",
         "35403.23903946014"
        ],
        [
         "7",
         "24724.0",
         "23714.834922626393"
        ],
        [
         "8",
         "29488.0",
         "29058.456263136606"
        ],
        [
         "9",
         "123182.0",
         "124688.33260340504"
        ],
        [
         "10",
         "5710.0",
         "5155.89750227902"
        ],
        [
         "11",
         "47042.0",
         "47015.15480639415"
        ],
        [
         "12",
         "5702.0",
         "5155.89750227902"
        ],
        [
         "13",
         "5382.0",
         "5308.924610988779"
        ],
        [
         "14",
         "26443.0",
         "25242.720509873572"
        ],
        [
         "15",
         "7735.0",
         "8288.1571025769"
        ],
        [
         "16",
         "49386.0",
         "48473.90129524111"
        ],
        [
         "17",
         "11209.0",
         "11532.373405050377"
        ],
        [
         "18",
         "5768.0",
         "6173.548693081061"
        ],
        [
         "19",
         "32124.0",
         "32248.653807200306"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Réel</th>\n",
       "      <th>Prédit_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5191.0</td>\n",
       "      <td>4627.772926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6581.0</td>\n",
       "      <td>6733.117870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44592.0</td>\n",
       "      <td>45384.846785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7755.0</td>\n",
       "      <td>7663.381414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5916.0</td>\n",
       "      <td>5155.897502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19169.0</td>\n",
       "      <td>17345.140658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36117.0</td>\n",
       "      <td>35403.239039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24724.0</td>\n",
       "      <td>23714.834923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29488.0</td>\n",
       "      <td>29058.456263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123182.0</td>\n",
       "      <td>124688.332603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5710.0</td>\n",
       "      <td>5155.897502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>47042.0</td>\n",
       "      <td>47015.154806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5702.0</td>\n",
       "      <td>5155.897502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5382.0</td>\n",
       "      <td>5308.924611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26443.0</td>\n",
       "      <td>25242.720510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7735.0</td>\n",
       "      <td>8288.157103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>49386.0</td>\n",
       "      <td>48473.901295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11209.0</td>\n",
       "      <td>11532.373405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5768.0</td>\n",
       "      <td>6173.548693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32124.0</td>\n",
       "      <td>32248.653807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Réel      Prédit_RF\n",
       "0     5191.0    4627.772926\n",
       "1     6581.0    6733.117870\n",
       "2    44592.0   45384.846785\n",
       "3     7755.0    7663.381414\n",
       "4     5916.0    5155.897502\n",
       "5    19169.0   17345.140658\n",
       "6    36117.0   35403.239039\n",
       "7    24724.0   23714.834923\n",
       "8    29488.0   29058.456263\n",
       "9   123182.0  124688.332603\n",
       "10    5710.0    5155.897502\n",
       "11   47042.0   47015.154806\n",
       "12    5702.0    5155.897502\n",
       "13    5382.0    5308.924611\n",
       "14   26443.0   25242.720510\n",
       "15    7735.0    8288.157103\n",
       "16   49386.0   48473.901295\n",
       "17   11209.0   11532.373405\n",
       "18    5768.0    6173.548693\n",
       "19   32124.0   32248.653807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tableau Comparatif des Performances des Modèles (mis à jour) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Training Time (s)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Best Params",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "23a7b756-9ffe-49f7-94bc-250286e99d52",
       "rows": [
        [
         "Random Forest (Tuned)",
         "1036.76216047442",
         "7202.94019069219",
         "0.9482085460005488",
         "165.89933490753174",
         "{'criterion': 'squared_error', 'max_depth': 10, 'n_estimators': 200}"
        ],
        [
         "Decision Tree (Tuned)",
         "2732.1685298323846",
         "7851.749471670067",
         "0.9384580356560794",
         "5.241214990615845",
         "{'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2}"
        ],
        [
         "Linear Regression",
         "4758.180572508502",
         "10938.450754904703",
         "0.8805599110306747",
         "0.15970587730407715",
         "N/A"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest (Tuned)</th>\n",
       "      <td>1036.762160</td>\n",
       "      <td>7202.940191</td>\n",
       "      <td>0.948209</td>\n",
       "      <td>165.899335</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree (Tuned)</th>\n",
       "      <td>2732.168530</td>\n",
       "      <td>7851.749472</td>\n",
       "      <td>0.938458</td>\n",
       "      <td>5.241215</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>4758.180573</td>\n",
       "      <td>10938.450755</td>\n",
       "      <td>0.880560</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MAE          RMSE        R2  Training Time (s)  \\\n",
       "Random Forest (Tuned)  1036.762160   7202.940191  0.948209         165.899335   \n",
       "Decision Tree (Tuned)  2732.168530   7851.749472  0.938458           5.241215   \n",
       "Linear Regression      4758.180573  10938.450755  0.880560           0.159706   \n",
       "\n",
       "                                                             Best Params  \n",
       "Random Forest (Tuned)  {'criterion': 'squared_error', 'max_depth': 10...  \n",
       "Decision Tree (Tuned)  {'criterion': 'squared_error', 'max_depth': 5,...  \n",
       "Linear Regression                                                    N/A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELLULE 7 : 3.3. Forêts Aléatoires (RandomForestRegressor) avec Ajustement des Hyperparamètres\n",
    "\n",
    "if 'X_train' in locals():\n",
    "    print(\"\\n--- 3.3. Entraînement et Ajustement des Hyperparamètres pour RandomForestRegressor ---\")\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    # Définir une grille d'hyperparamètres plus ciblée pour RandomForest\n",
    "    # RandomForest peut être long à entraîner avec une grille large.\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': [50, 100, 150, 200], # Nombre d'arbres dans la forêt\n",
    "        'criterion': ['squared_error'], # 'absolute_error' est très lent pour RF, 'friedman_mse' est une alternative\n",
    "        'max_depth': [None, 5, 10, 15, 20],      # Profondeur max des arbres (similaire à DT)\n",
    "        # 'min_samples_split': [2, 4], # Nombre min d'échantillons pour diviser un nœud\n",
    "        # 'min_samples_leaf': [1, 2], # Nombre min d'échantillons par feuille (peut être ajouté)\n",
    "        # 'max_features': ['sqrt', 'log2'] # Nombre de features à considérer pour la meilleure division (peut être ajouté)\n",
    "    }\n",
    "    # Pour un premier essai, cette grille est raisonnable.\n",
    "    # Si le temps le permet, vous pouvez l'étendre.\n",
    "\n",
    "    # Initialiser GridSearchCV\n",
    "    grid_search_rf = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1), # n_jobs dans RF pour l'entraînement des arbres\n",
    "        param_grid=param_grid_rf,\n",
    "        cv=3, # Réduire le nombre de plis pour accélérer si nécessaire (5 est standard)\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1, # n_jobs dans GridSearchCV pour les plis de CV\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"Ajustement des hyperparamètres pour RandomForestRegressor en cours (CV={grid_search_rf.cv})...\")\n",
    "    start_time_rf_grid = time.time()\n",
    "    grid_search_rf.fit(X_train, y_train)\n",
    "    end_time_rf_grid = time.time()\n",
    "    grid_search_time_rf = end_time_rf_grid - start_time_rf_grid\n",
    "    print(f\"Ajustement terminé en {grid_search_time_rf:.2f} secondes.\")\n",
    "\n",
    "    # Meilleurs hyperparamètres et score\n",
    "    print(f\"\\nMeilleurs hyperparamètres trouvés pour RandomForestRegressor : {grid_search_rf.best_params_}\")\n",
    "    print(f\"Meilleur score (neg_mean_squared_error) de validation croisée : {grid_search_rf.best_score_:.4f}\")\n",
    "    \n",
    "    # Meilleur estimateur\n",
    "    best_rf_model = grid_search_rf.best_estimator_\n",
    "    \n",
    "    # Prédictions\n",
    "    predictions_rf = best_rf_model.predict(X_test)\n",
    "    \n",
    "    # Évaluation\n",
    "    mae_rf = mean_absolute_error(y_test, predictions_rf)\n",
    "    rmse_rf = np.sqrt(mean_squared_error(y_test, predictions_rf))\n",
    "    r2_rf = r2_score(y_test, predictions_rf)\n",
    "    \n",
    "    print(\"\\n--- Évaluation du Modèle RandomForestRegressor (avec meilleurs hyperparamètres) ---\")\n",
    "    print(f\"MAE: {mae_rf:.2f} DH\")\n",
    "    print(f\"RMSE: {rmse_rf:.2f} DH\")\n",
    "    print(f\"R²: {r2_rf:.4f}\")\n",
    "    \n",
    "    # Stocker les performances\n",
    "    model_performance['Random Forest (Tuned)'] = {\n",
    "        'MAE': mae_rf,\n",
    "        'RMSE': rmse_rf,\n",
    "        'R2': r2_rf,\n",
    "        'Training Time (s)': grid_search_time_rf,\n",
    "        'Best Params': grid_search_rf.best_params_\n",
    "    }\n",
    "\n",
    "    print(\"\\n--- Aperçu des Prédictions vs Valeurs Réelles (Random Forest) ---\")\n",
    "    df_predictions_rf = pd.DataFrame({'Réel': y_test.values, 'Prédit_RF': predictions_rf})\n",
    "    display(df_predictions_rf.head(20))\n",
    "\n",
    "    # Mettre à jour et afficher le tableau comparatif\n",
    "    print(\"\\n--- Tableau Comparatif des Performances des Modèles (mis à jour) ---\")\n",
    "    performance_df = pd.DataFrame.from_dict(model_performance, orient='index')\n",
    "    display(performance_df.sort_values(by='RMSE', ascending=True))\n",
    "\n",
    "else:\n",
    "    print(\"Veuillez d'abord charger et prétraiter les données.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.4. Entraînement et Ajustement des Hyperparamètres pour GradientBoostingRegressor ---\n",
      "Ajustement des hyperparamètres pour GradientBoostingRegressor en cours (CV=3)...\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajustement terminé en 125.82 secondes.\n",
      "\n",
      "Meilleurs hyperparamètres trouvés pour GradientBoostingRegressor : {'learning_rate': 0.1, 'loss': 'squared_error', 'n_estimators': 300, 'subsample': 1.0}\n",
      "Meilleur score (neg_mean_squared_error) de validation croisée : -21200511.8167\n",
      "\n",
      "--- Évaluation du Modèle GradientBoostingRegressor (avec meilleurs hyperparamètres) ---\n",
      "MAE: 825.42 DH\n",
      "RMSE: 6789.42 DH\n",
      "R²: 0.9540\n",
      "\n",
      "--- Aperçu des Prédictions vs Valeurs Réelles (Gradient Boosting) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Réel",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Prédit_GBR",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "eb152402-53e0-42c3-a9da-9f7e124aa071",
       "rows": [
        [
         "0",
         "5191.0",
         "5134.509173796655"
        ],
        [
         "1",
         "6581.0",
         "6925.558080711522"
        ],
        [
         "2",
         "44592.0",
         "45360.25330755048"
        ],
        [
         "3",
         "7755.0",
         "8113.6058416895685"
        ],
        [
         "4",
         "5916.0",
         "5937.097865916152"
        ],
        [
         "5",
         "19169.0",
         "18849.403859287002"
        ],
        [
         "6",
         "36117.0",
         "37045.81629263906"
        ],
        [
         "7",
         "24724.0",
         "24121.518124764447"
        ],
        [
         "8",
         "29488.0",
         "31133.77308224121"
        ],
        [
         "9",
         "123182.0",
         "123694.61125964891"
        ],
        [
         "10",
         "5710.0",
         "5820.639530661268"
        ],
        [
         "11",
         "47042.0",
         "47157.871992539745"
        ],
        [
         "12",
         "5702.0",
         "6376.905919530833"
        ],
        [
         "13",
         "5382.0",
         "5355.734403703303"
        ],
        [
         "14",
         "26443.0",
         "25541.12540085103"
        ],
        [
         "15",
         "7735.0",
         "8262.205814937264"
        ],
        [
         "16",
         "49386.0",
         "50767.3159711429"
        ],
        [
         "17",
         "11209.0",
         "12245.054334038108"
        ],
        [
         "18",
         "5768.0",
         "6399.340289625918"
        ],
        [
         "19",
         "32124.0",
         "30975.33734593235"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Réel</th>\n",
       "      <th>Prédit_GBR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5191.0</td>\n",
       "      <td>5134.509174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6581.0</td>\n",
       "      <td>6925.558081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44592.0</td>\n",
       "      <td>45360.253308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7755.0</td>\n",
       "      <td>8113.605842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5916.0</td>\n",
       "      <td>5937.097866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19169.0</td>\n",
       "      <td>18849.403859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36117.0</td>\n",
       "      <td>37045.816293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24724.0</td>\n",
       "      <td>24121.518125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29488.0</td>\n",
       "      <td>31133.773082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123182.0</td>\n",
       "      <td>123694.611260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5710.0</td>\n",
       "      <td>5820.639531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>47042.0</td>\n",
       "      <td>47157.871993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5702.0</td>\n",
       "      <td>6376.905920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5382.0</td>\n",
       "      <td>5355.734404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26443.0</td>\n",
       "      <td>25541.125401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7735.0</td>\n",
       "      <td>8262.205815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>49386.0</td>\n",
       "      <td>50767.315971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11209.0</td>\n",
       "      <td>12245.054334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5768.0</td>\n",
       "      <td>6399.340290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32124.0</td>\n",
       "      <td>30975.337346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Réel     Prédit_GBR\n",
       "0     5191.0    5134.509174\n",
       "1     6581.0    6925.558081\n",
       "2    44592.0   45360.253308\n",
       "3     7755.0    8113.605842\n",
       "4     5916.0    5937.097866\n",
       "5    19169.0   18849.403859\n",
       "6    36117.0   37045.816293\n",
       "7    24724.0   24121.518125\n",
       "8    29488.0   31133.773082\n",
       "9   123182.0  123694.611260\n",
       "10    5710.0    5820.639531\n",
       "11   47042.0   47157.871993\n",
       "12    5702.0    6376.905920\n",
       "13    5382.0    5355.734404\n",
       "14   26443.0   25541.125401\n",
       "15    7735.0    8262.205815\n",
       "16   49386.0   50767.315971\n",
       "17   11209.0   12245.054334\n",
       "18    5768.0    6399.340290\n",
       "19   32124.0   30975.337346"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tableau Comparatif des Performances des Modèles (mis à jour) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Training Time (s)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Best Params",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a9a8e682-3810-4106-96dc-78329fc3a4ff",
       "rows": [
        [
         "Gradient Boosting (Tuned)",
         "825.4208140140613",
         "6789.417881390222",
         "0.9539845613841873",
         "125.82095694541931",
         "{'learning_rate': 0.1, 'loss': 'squared_error', 'n_estimators': 300, 'subsample': 1.0}"
        ],
        [
         "MLP Regressor (Tuned)",
         "927.4817407202809",
         "6898.479327676589",
         "0.952494354812913",
         "144.37901997566223",
         "{'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.005, 'max_iter': 500, 'solver': 'adam'}"
        ],
        [
         "Random Forest (Tuned)",
         "1036.76216047442",
         "7202.94019069219",
         "0.9482085460005488",
         "165.89933490753174",
         "{'criterion': 'squared_error', 'max_depth': 10, 'n_estimators': 200}"
        ],
        [
         "Decision Tree (Tuned)",
         "2732.1685298323846",
         "7851.749471670067",
         "0.9384580356560794",
         "5.241214990615845",
         "{'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2}"
        ],
        [
         "Linear Regression",
         "4758.180572508502",
         "10938.450754904703",
         "0.8805599110306747",
         "0.15970587730407715",
         "N/A"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting (Tuned)</th>\n",
       "      <td>825.420814</td>\n",
       "      <td>6789.417881</td>\n",
       "      <td>0.953985</td>\n",
       "      <td>125.820957</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'squared_error'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Regressor (Tuned)</th>\n",
       "      <td>927.481741</td>\n",
       "      <td>6898.479328</td>\n",
       "      <td>0.952494</td>\n",
       "      <td>144.379020</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (Tuned)</th>\n",
       "      <td>1036.762160</td>\n",
       "      <td>7202.940191</td>\n",
       "      <td>0.948209</td>\n",
       "      <td>165.899335</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree (Tuned)</th>\n",
       "      <td>2732.168530</td>\n",
       "      <td>7851.749472</td>\n",
       "      <td>0.938458</td>\n",
       "      <td>5.241215</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>4758.180573</td>\n",
       "      <td>10938.450755</td>\n",
       "      <td>0.880560</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   MAE          RMSE        R2  \\\n",
       "Gradient Boosting (Tuned)   825.420814   6789.417881  0.953985   \n",
       "MLP Regressor (Tuned)       927.481741   6898.479328  0.952494   \n",
       "Random Forest (Tuned)      1036.762160   7202.940191  0.948209   \n",
       "Decision Tree (Tuned)      2732.168530   7851.749472  0.938458   \n",
       "Linear Regression          4758.180573  10938.450755  0.880560   \n",
       "\n",
       "                           Training Time (s)  \\\n",
       "Gradient Boosting (Tuned)         125.820957   \n",
       "MLP Regressor (Tuned)             144.379020   \n",
       "Random Forest (Tuned)             165.899335   \n",
       "Decision Tree (Tuned)               5.241215   \n",
       "Linear Regression                   0.159706   \n",
       "\n",
       "                                                                 Best Params  \n",
       "Gradient Boosting (Tuned)  {'learning_rate': 0.1, 'loss': 'squared_error'...  \n",
       "MLP Regressor (Tuned)      {'activation': 'relu', 'alpha': 0.001, 'hidden...  \n",
       "Random Forest (Tuned)      {'criterion': 'squared_error', 'max_depth': 10...  \n",
       "Decision Tree (Tuned)      {'criterion': 'squared_error', 'max_depth': 5,...  \n",
       "Linear Regression                                                        N/A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELLULE 8 : 3.4. Gradient Boosting Regressor avec Ajustement des Hyperparamètres\n",
    "\n",
    "if 'X_train' in locals():\n",
    "    print(\"\\n--- 3.4. Entraînement et Ajustement des Hyperparamètres pour GradientBoostingRegressor ---\")\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "    # Définir une grille d'hyperparamètres pour GradientBoostingRegressor\n",
    "    # Gradient Boosting peut aussi être long à entraîner.\n",
    "    param_grid_gbr = {\n",
    "        'loss': ['squared_error'], # Ajout de 'absolute_error'\n",
    "        'n_estimators': [100, 200, 300],          \n",
    "        'learning_rate': [0.01, 0.1, 0.2],                \n",
    "        'subsample': [0.5, 0.8, 1.0]            \n",
    "    }\n",
    "    # Cette grille est un bon point de départ.\n",
    "\n",
    "    # Initialiser GridSearchCV\n",
    "    grid_search_gbr = GridSearchCV(\n",
    "        estimator=GradientBoostingRegressor(random_state=RANDOM_STATE),\n",
    "        param_grid=param_grid_gbr,\n",
    "        cv=3, # Maintenir cv=3 pour la vitesse, augmenter à 5 si le temps le permet\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"Ajustement des hyperparamètres pour GradientBoostingRegressor en cours (CV={grid_search_gbr.cv})...\")\n",
    "    start_time_gbr_grid = time.time()\n",
    "    grid_search_gbr.fit(X_train, y_train)\n",
    "    end_time_gbr_grid = time.time()\n",
    "    grid_search_time_gbr = end_time_gbr_grid - start_time_gbr_grid\n",
    "    print(f\"Ajustement terminé en {grid_search_time_gbr:.2f} secondes.\")\n",
    "\n",
    "    # Meilleurs hyperparamètres et score\n",
    "    print(f\"\\nMeilleurs hyperparamètres trouvés pour GradientBoostingRegressor : {grid_search_gbr.best_params_}\")\n",
    "    print(f\"Meilleur score (neg_mean_squared_error) de validation croisée : {grid_search_gbr.best_score_:.4f}\")\n",
    "    \n",
    "    # Meilleur estimateur\n",
    "    best_gbr_model = grid_search_gbr.best_estimator_\n",
    "    \n",
    "    # Prédictions\n",
    "    predictions_gbr = best_gbr_model.predict(X_test)\n",
    "    \n",
    "    # Évaluation\n",
    "    mae_gbr = mean_absolute_error(y_test, predictions_gbr)\n",
    "    rmse_gbr = np.sqrt(mean_squared_error(y_test, predictions_gbr))\n",
    "    r2_gbr = r2_score(y_test, predictions_gbr)\n",
    "    \n",
    "    print(\"\\n--- Évaluation du Modèle GradientBoostingRegressor (avec meilleurs hyperparamètres) ---\")\n",
    "    print(f\"MAE: {mae_gbr:.2f} DH\")\n",
    "    print(f\"RMSE: {rmse_gbr:.2f} DH\")\n",
    "    print(f\"R²: {r2_gbr:.4f}\")\n",
    "    \n",
    "    # Stocker les performances\n",
    "    model_performance['Gradient Boosting (Tuned)'] = {\n",
    "        'MAE': mae_gbr,\n",
    "        'RMSE': rmse_gbr,\n",
    "        'R2': r2_gbr,\n",
    "        'Training Time (s)': grid_search_time_gbr,\n",
    "        'Best Params': grid_search_gbr.best_params_\n",
    "    }\n",
    "\n",
    "    print(\"\\n--- Aperçu des Prédictions vs Valeurs Réelles (Gradient Boosting) ---\")\n",
    "    df_predictions_gbr = pd.DataFrame({'Réel': y_test.values, 'Prédit_GBR': predictions_gbr})\n",
    "    display(df_predictions_gbr.head(20))\n",
    "\n",
    "    # Mettre à jour et afficher le tableau comparatif\n",
    "    print(\"\\n--- Tableau Comparatif des Performances des Modèles (mis à jour) ---\")\n",
    "    performance_df = pd.DataFrame.from_dict(model_performance, orient='index')\n",
    "    display(performance_df.sort_values(by='RMSE', ascending=True))\n",
    "\n",
    "else:\n",
    "    print(\"Veuillez d'abord charger et prétraiter les données.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3.5. Entraînement et Ajustement des Hyperparamètres pour MLPRegressor ---\n",
      "Ajustement des hyperparamètres pour MLPRegressor en cours (CV=2)...\n",
      "Cela peut prendre beaucoup de temps...\n",
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCela peut prendre beaucoup de temps...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m start_time_mlp_grid = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mgrid_search_mlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Utiliser X_train_scaled\u001b[39;00m\n\u001b[32m     36\u001b[39m end_time_mlp_grid = time.time()\n\u001b[32m     37\u001b[39m grid_search_time_mlp = end_time_mlp_grid - start_time_mlp_grid\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/ML/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/ML/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/ML/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/ML/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/ML/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/ML/.venv/lib/python3.12/site-packages/joblib/parallel.py:2071\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2065\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2071\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/ML/.venv/lib/python3.12/site-packages/joblib/parallel.py:1681\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1684\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Projects/ML/.venv/lib/python3.12/site-packages/joblib/parallel.py:1799\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1789\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1794\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1797\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1799\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1800\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1802\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1803\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1810\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# CELLULE 9 : 3.5. Réseaux de Neurones (MLPRegressor) avec Ajustement des Hyperparamètres\n",
    "\n",
    "if 'X_train' in locals():\n",
    "    print(\"\\n--- 3.5. Entraînement et Ajustement des Hyperparamètres pour MLPRegressor ---\")\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    from sklearn.preprocessing import StandardScaler # S'assurer que les données sont bien standardisées pour MLP\n",
    "\n",
    "    # Note: Les données X_train, X_test devraient déjà être standardisées par preprocess_data_.py\n",
    "    # Si ce n'était pas le cas, il faudrait le faire ici spécifiquement pour MLP.\n",
    "\n",
    "    # Définir une grille d'hyperparamètres TRÈS SIMPLE pour MLPRegressor pour un premier essai\n",
    "    # L'exploration d'architectures de réseau peut être très longue.\n",
    "    param_grid_mlp = { # Remplacer par la grille simplifiée\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 100)],\n",
    "        'activation': ['relu'],\n",
    "        'solver': ['adam'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate_init': [0.001, 0.01],\n",
    "        'max_iter': [300, 500], # S'assurer que early_stopping est activé dans l'estimateur\n",
    "        # 'batch_size': [32, 64] # Pourrait être testé dans une seconde passe\n",
    "    }\n",
    "\n",
    "    grid_search_mlp = GridSearchCV(\n",
    "        estimator=MLPRegressor(random_state=RANDOM_STATE, early_stopping=True, n_iter_no_change=15, tol=1e-4), # Ajuster n_iter_no_change et tol\n",
    "        param_grid=param_grid_mlp,\n",
    "        cv=2, # Maintenir cv=2 ou 3 pour la vitesse\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"Ajustement des hyperparamètres pour MLPRegressor en cours (CV={grid_search_mlp.cv})...\")\n",
    "    print(\"Cela peut prendre beaucoup de temps...\")\n",
    "    start_time_mlp_grid = time.time()\n",
    "    grid_search_mlp.fit(X_train, y_train) # Utiliser X_train_scaled\n",
    "    end_time_mlp_grid = time.time()\n",
    "    grid_search_time_mlp = end_time_mlp_grid - start_time_mlp_grid\n",
    "    print(f\"Ajustement terminé en {grid_search_time_mlp:.2f} secondes.\")\n",
    "\n",
    "    # Meilleurs hyperparamètres et score\n",
    "    print(f\"\\nMeilleurs hyperparamètres trouvés pour MLPRegressor : {grid_search_mlp.best_params_}\")\n",
    "    print(f\"Meilleur score (neg_mean_squared_error) de validation croisée : {grid_search_mlp.best_score_:.4f}\")\n",
    "    \n",
    "    # Meilleur estimateur\n",
    "    best_mlp_model = grid_search_mlp.best_estimator_\n",
    "    \n",
    "    # Prédictions\n",
    "    predictions_mlp = best_mlp_model.predict(X_test) # Utiliser X_test_scaled\n",
    "    \n",
    "    # Évaluation\n",
    "    mae_mlp = mean_absolute_error(y_test, predictions_mlp)\n",
    "    rmse_mlp = np.sqrt(mean_squared_error(y_test, predictions_mlp))\n",
    "    r2_mlp = r2_score(y_test, predictions_mlp)\n",
    "    \n",
    "    print(\"\\n--- Évaluation du Modèle MLPRegressor (avec meilleurs hyperparamètres) ---\")\n",
    "    print(f\"MAE: {mae_mlp:.2f} DH\")\n",
    "    print(f\"RMSE: {rmse_mlp:.2f} DH\")\n",
    "    print(f\"R²: {r2_mlp:.4f}\")\n",
    "    \n",
    "    # Stocker les performances\n",
    "    model_performance['MLP Regressor (Tuned)'] = {\n",
    "        'MAE': mae_mlp,\n",
    "        'RMSE': rmse_mlp,\n",
    "        'R2': r2_mlp,\n",
    "        'Training Time (s)': grid_search_time_mlp,\n",
    "        'Best Params': grid_search_mlp.best_params_\n",
    "    }\n",
    "\n",
    "    print(\"\\n--- Aperçu des Prédictions vs Valeurs Réelles (MLP Regressor) ---\")\n",
    "    df_predictions_mlp = pd.DataFrame({'Réel': y_test.values, 'Prédit_MLP': predictions_mlp})\n",
    "    display(df_predictions_mlp.head(20))\n",
    "\n",
    "    # Mettre à jour et afficher le tableau comparatif\n",
    "    print(\"\\n--- Tableau Comparatif des Performances des Modèles (mis à jour) ---\")\n",
    "    performance_df = pd.DataFrame.from_dict(model_performance, orient='index')\n",
    "    display(performance_df.sort_values(by='RMSE', ascending=True))\n",
    "\n",
    "else:\n",
    "    print(\"Veuillez d'abord charger et prétraiter les données.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tableau Comparatif des Performances des Modèles ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Training Time (s)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Best Params",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dc1287f5-426d-4a2b-a4a2-77f52a803ac1",
       "rows": [
        [
         "Random Forest (Tuned)",
         "1036.76216047442",
         "7202.94019069219",
         "0.9482085460005488",
         "165.89933490753174",
         "{'criterion': 'squared_error', 'max_depth': 10, 'n_estimators': 200}"
        ],
        [
         "Decision Tree (Tuned)",
         "2732.1685298323846",
         "7851.749471670067",
         "0.9384580356560794",
         "5.241214990615845",
         "{'criterion': 'squared_error', 'max_depth': 5, 'min_samples_split': 2}"
        ],
        [
         "Linear Regression",
         "4758.180572508502",
         "10938.450754904703",
         "0.8805599110306747",
         "0.15970587730407715",
         "N/A"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest (Tuned)</th>\n",
       "      <td>1036.762160</td>\n",
       "      <td>7202.940191</td>\n",
       "      <td>0.948209</td>\n",
       "      <td>165.899335</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree (Tuned)</th>\n",
       "      <td>2732.168530</td>\n",
       "      <td>7851.749472</td>\n",
       "      <td>0.938458</td>\n",
       "      <td>5.241215</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>4758.180573</td>\n",
       "      <td>10938.450755</td>\n",
       "      <td>0.880560</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MAE          RMSE        R2  Training Time (s)  \\\n",
       "Random Forest (Tuned)  1036.762160   7202.940191  0.948209         165.899335   \n",
       "Decision Tree (Tuned)  2732.168530   7851.749472  0.938458           5.241215   \n",
       "Linear Regression      4758.180573  10938.450755  0.880560           0.159706   \n",
       "\n",
       "                                                             Best Params  \n",
       "Random Forest (Tuned)  {'criterion': 'squared_error', 'max_depth': 10...  \n",
       "Decision Tree (Tuned)  {'criterion': 'squared_error', 'max_depth': 5,...  \n",
       "Linear Regression                                                    N/A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELLULE 6 : Affichage du Tableau Comparatif des Performances\n",
    "\n",
    "if model_performance:\n",
    "    print(\"\\n--- Tableau Comparatif des Performances des Modèles ---\")\n",
    "    performance_df = pd.DataFrame.from_dict(model_performance, orient='index')\n",
    "    display(performance_df.sort_values(by='RMSE', ascending=True))\n",
    "else:\n",
    "    print(\"Aucun modèle n'a encore été entraîné et évalué.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
